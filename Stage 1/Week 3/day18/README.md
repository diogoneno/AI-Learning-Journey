# â“ Day 18: AI-Powered Q&A (Gradio UI + Vector Search)

## ğŸ¯ Learning Objectives
- Build an **interactive Q&A web app** with **Gradio**.
- Ingest uploaded `.txt` content into **ChromaDB** with **HF embeddings**.
- Retrieve top-k chunks and **ground answers** with a local LLM via **LM Studio**.
- Keep the whole flow **local and private**.

## ğŸ§© What Youâ€™ll Build
A browser app where you:
1) Upload a `.txt` document,
2) Itâ€™s embedded + indexed in Chroma,
3) You ask questions; answers are produced using retrieved context.

## ğŸ”§ Setup
```bash
pip install -r requirements.txt
# Start LM Studio, load a model, enable local API server.
