AI-Learning-Journey
Overview
This repository documents the first steps of my journey in learning AI engineering. Today’s focus is on exploring Large Language Models (LLMs) and understanding how to interact with them using APIs. By the end of today’s session, I will have a working Python script that connects to OpenAI’s API and returns a response from an LLM.

Today’s Focus
What I’m learning:

What LLMs are and how they’re used.
How to set up and use the OpenAI API.
Basic API authentication and making a simple request.
What’s included:

test_openai_api.py: A Python script that demonstrates making an API call to OpenAI’s LLM and returning a response.
Step-by-step instructions on how to run the script and view the output.
Step-by-Step Instructions:
1. Install Python (if not already installed):

Go to https://www.python.org/downloads/ and download the latest version of Python for your operating system.
Follow the installation prompts. Make sure to add Python to your system’s PATH during installation.
2. Install the required library:

Open a terminal or command prompt.
Run the following command to install the OpenAI Python library:
bash
Copy
Edit
pip install openai
3. Download the script:

Save the test_openai_api.py script (provided in this repository) to a folder on your computer.
4. Set your API key using environment variables:

Use environment variables to keep your API key private.
Make sure the script includes:
python
Copy
Edit
import os
openai.api_key = os.getenv("OPENAI_API_KEY")
Set the environment variable OPENAI_API_KEY on your local machine:
Windows (Command Prompt):
bash
Copy
Edit
set OPENAI_API_KEY=your-api-key
macOS/Linux (Terminal):
bash
Copy
Edit
export OPENAI_API_KEY=your-api-key
5. Run the script:

In your terminal, navigate to the folder containing test_openai_api.py. For example:
bash
Copy
Edit
cd /path/to/your/folder
Run the script:
bash
Copy
Edit
python test_openai_api.py
6. View the output:

The script will print a response generated by the OpenAI API to your terminal. This is the result of your prompt being processed by the LLM.
